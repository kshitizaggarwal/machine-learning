#importing libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

#importing dataset
dataset = pd.read_csv("data_tumor_classification.csv")

#X and Y_actual
X = dataset.iloc[:,2:32].values
Y_actual = dataset.iloc[:,1:2].replace(to_replace = ['M','B'],value=[0,1]).values

#normalizating the dataset
for i in range (len(X.T)):
    X[:,i:i+1] = X[:,i:i+1]/X[:,i:i+1].max()

'***************** NOTE:- Malignant=0 and Benign=1***********************'

''' PCA
cov = dataset.iloc[:,2:32].corr()
u, s, vh = np.linalg.svd(cov)
'''

#functions
#sigmoid function
def sigmoid(x,m,c):
    z = np.matmul(x,m)
    b = np.exp(-z)
    return 1/(1 + b)

#error function
def cross_entropy_loss(predY,y):
    try:
        b = (y* np.log(predY) + ( 1 - y )* np.log ( 1 - predY ))
        return np.mean(-b) 
    except:
        print("error")

#derivative function
def derivative(predY, x, y):
    b = np.matmul(x.T,(predY - y))
    return b

#accuracy function
def accuracy(Y_act,Y_pred):
    counter = 0
    for i in range(len(Y_act)):
        if Y_act[i] == Y_pred[i]:
            counter = counter +1
    return (counter/len(Y_act))*100

#user defined variables
features = len(X.T)                 #no.of features
c = np.random.randn()               #intercept
m = np.random.randn(features, 1)    #m/slope
iterations = 4500                    #steps
alpha = 0.0000009               #learning rate

errors = []
#training the dataset
for i in range(iterations):
#    print(i)
    predY = sigmoid(X,m,c)
    errors.append(cross_entropy_loss(predY,Y_actual))
    m = m - alpha * derivative(predY,X,Y_actual)
    c = c - alpha * derivative(predY,np.ones(X.shape),Y_actual)
    
plt.plot(errors)

Y_pred=[]
for i in range(len(predY)):
    Y_pred.append(round(float(predY[i])))

#finding accuracy for the algorithm
print('accuracy = ',accuracy(Y_actual,Y_pred))
    
